
# ğŸ¤ Audio Deepfake Detection using RawNet2 (ASVspoof 2019)

A deep learning-based solution for detecting audio deepfakes using the **RawNet2** architecture. Trained on the **ASVspoof 2019 Logical Access (LA)** dataset, this project classifies audio clips as either genuine (bonafide) or fake (spoofed).

---

## ğŸ” 1. Why Audio Deepfake Detection?

With the rapid evolution of AI voice synthesis (like deepfake voice cloning), detecting audio-based spoofing has become critical for protecting biometric authentication systems, online meetings, and voice-activated devices from malicious attacks.

---

## ğŸ¯ 2. Why RawNet2?

We explored three models for this project:

1. **RawNet2**
2. **LCNN (Light CNN)**
3. **X-vector + Cosine Scoring**

After evaluating architecture complexity, performance, and adaptability to raw waveform inputs, we selected **RawNet2** as the final model.

### ğŸ” 2.1 Model Comparison Table

| Model                 | Input Type       | Architecture Type         | Feature Extraction | Accuracy (on LA) | Complexity | Real-Time Capability | Notes                                                                 |
|----------------------|------------------|----------------------------|---------------------|------------------|------------|-----------------------|-----------------------------------------------------------------------|
| **RawNet2**           | Raw Waveform     | CNN + GRU (End-to-End)     | âœ… Learned features | **85â€“90%**        | Moderate   | âœ… Yes                 | Best performance, real-time ready, no manual preprocessing required   |
| **LCNN (Light CNN)**  | Spectrogram (FFT)| CNN + Max-Feature-Map      | âŒ Manual features  | ~82â€“85%           | High       | âŒ No                  | Heavy preprocessing and slower inference                              |
| **X-vector + Cosine**| MFCC             | DNN + Cosine Similarity    | âŒ Manual features  | ~78â€“80%           | Low        | âœ… Yes                 | Simple but less accurate, mainly designed for speaker verification    |

### âœ… 2.2 Why RawNet2 Wins

- **End-to-End Learning**: Processes raw waveform input directly, removing the need for manual feature extraction.
- **Performance**: Outperforms other models in terms of accuracy and adaptability to deepfake variations.
- **Efficiency**: Lightweight and real-time capable, suitable for real-world deployment.
- **Designed for Anti-Spoofing**: RawNet2 was proposed for voice spoof detection challenges and is optimized for such tasks.

---

## ğŸ“‚ 3. Dataset: ASVspoof 2019 (Logical Access)

- **Dataset Link**: [ASVspoof 2019 - Logical Access](https://datashare.ed.ac.uk/handle/10283/3336)
- **Subset Used**: `train`, `dev`, and `eval` under the `LA` folder
- **Formats**: `.flac` audio files + protocol `.txt` files
- âš ï¸ **Note**: Due to licensing restrictions, the dataset must be downloaded manually.

---

## ğŸš€ 4. Installation

```bash
git clone https://github.com/anitripathi/audio-deepfake-detection-momenta.git
cd audio-deepfake-detection-momenta

# (Optional) Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸ“ˆ 5. Usage

### 5.1 Train the model

```bash
python train.py
```

### 5.2 Visualize an audio waveform

```bash
python waveform_plot.py
```

### 5.3 Inference (coming soon)

The inference script will allow you to test your own audio samples with the trained RawNet2 model.

---

## ğŸ§  6. Model Architecture: RawNet2

```
Input: Raw waveform
 â””â”€â”€ Conv1D Layers (feature extractor)
     â””â”€â”€ Residual Blocks
         â””â”€â”€ GRU Layer (temporal encoding)
             â””â”€â”€ Fully Connected + Softmax
Output: Bonafide / Spoof
```

- Combines convolutional feature extraction with temporal modeling.
- End-to-end anti-spoofing architecture tailored for biometric ASV systems.

---

## ğŸ“Š 7. Results

| Metric       | Value     |
|--------------|-----------|
| Accuracy     | ~85â€“90%   |
| Epochs       | 5         |
| Optimizer    | Adam      |
| Loss         | BCE Loss  |

> Results may vary based on the system and training splits.

---

## ğŸ“ 8. Folder Structure

```
audio-deepfake-detection-momenta/
â”œâ”€â”€ models/                  # RawNet2 model definition
â”œâ”€â”€ train.py                 # Model training script
â”œâ”€â”€ visualize.ipynb          # Audio waveform visualization
â”œâ”€â”€ UTILS/                   # Utility functions and dataset loader
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md                # Project overview
```

---

## ğŸ‘¥ 9. Contributing

Pull requests are welcome! If you find bugs or want to improve the project, feel free to fork and submit PRs.

---

## ğŸ‘¨â€ğŸ’¼ 10. Author

**Anivesh Tripathi**  
ğŸ“§ aniveshtripathi.in@gmail.com  
ğŸ”— [GitHub](https://github.com/anitripathi)

---

## ğŸŒŸ 11. Acknowledgements

- ASVspoof 2019 Organizing Team  
- RawNet2 Paper by Heo et al.  
- PyTorch and Open-Source ML Community
